---
title: "Data Mining HW2"
output: html_document
date: "2024-10-07"
---

```{r setup, include=FALSE}
library(datasets)
library(arules)
library(arulesViz)
library(ggplot2)
library(dplyr)
library(rpart)
library(rpart.plot)
library(TH.data)
library(ISLR2)
library(lattice)
library(stats)
library(rattle)
library(RColorBrewer)
library(caret)
library(ROCR)
library(tidyverse)  
library(cluster)  
library(factoextra) 
library(gridExtra)
library(NbClust)
library(dendextend)
library(class)
library(ClustOfVar)
library(MASS)
library(kableExtra)
library(partykit)
library(dbscan)
library(AmesHousing)
library(reticulate)
```

```{r}
train <- read.csv('insurance_t.csv')
validation <- read.csv('insurance_v.csv')
train
```


```{r}
tree = rpart(INS ~ ., data=train, method='class',
 parms = list(split='gini')) 
summary(tree)
```

```{r}
print(tree)
```

```{r}
tree$variable.importance
varimp.data=data.frame(tree$variable.importance)
varimp.data$names=as.character(rownames(varimp.data))

ggplot(data=varimp.data,aes(x=names,y=tree.variable.importance))+geom_bar(stat="identity")+coord_flip()+labs(x="Variable Name",y="Variable Importance")
```

```{r}
tscores = predict(tree,type='class')
scores = predict(tree, validation, type='class')

##Training misclassification rate:
sum(tscores!=train$INS)/nrow(train)

### Test data:
sum(scores!=validation$INS)/nrow(validation)
```


```{r}
rpart.plot(tree)
```


```{r}
train = train %>% dplyr::select(-"BRANCH") %>% rename("Savings Account Balance" = "SAVBAL", "Money Market (Y/N)" = "MM", "CD Balance" = "CDBAL", "Account Age" = "ACCTAGE")

validation = validation %>% rename("Savings Account Balance" = "SAVBAL", "Money Market (Y/N)" = "MM", "CD Balance" = "CDBAL", "Account Age" = "ACCTAGE")

tree = rpart(INS ~ ., data=train, method='class',
 parms = list(split='gini')) 
summary(tree)

tree$variable.importance
varimp.data=data.frame(tree$variable.importance)
varimp.data$names=as.character(rownames(varimp.data))

ggplot(data=varimp.data,aes(x=names,y=tree.variable.importance))+geom_bar(stat="identity")+coord_flip()+labs(x="Variable Name",y="Variable Importance")

rpart.plot(tree)
```

```{r}
print(tree)
```


```{r}
tscores = predict(tree,type='class')
scores = predict(tree, validation, type='class')

##Training misclassification rate:
sum(tscores!=train$INS)/nrow(train)

### Validation data:
sum(scores!=validation$INS)/nrow(validation)
```

```{r}
library(caret) 
validation$INS = as.factor(validation$INS)
# Create the confusion matrix
confusionMatrix(scores, validation$INS)
```




```{r}
plot1 = rpart.plot(tree, 
           type = 2)
```

```{r}
###Lift (from classification trees)
scores1=predict(tree,validation,type="prob")
pred_val <-prediction(scores1[,2],validation$INS)
plot(performance(pred_val, measure="lift", x.measure="rpp"), colorize=TRUE)

# Calculating True Positive and False Positive Rate
perf_val <- performance(pred_val, "tpr", "fpr")
#Plot the ROC curve
plot(perf_val, col = "green", lwd = 1.5)

#Calculating KS statistics
ks1.tree <- max(attr(perf_val, "y.values")[[1]] - (attr(perf_val, "x.values")[[1]]))
ks1.tree
```


